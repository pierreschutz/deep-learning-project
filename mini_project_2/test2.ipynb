{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fwk.neural_nets as nn\n",
    "import fwk.optimizers as optim\n",
    "import fwk.data as data\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Disable auto_grad\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Global variables\n",
    "N_EPOCHS = 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.f = nn.Sequential(OrderedDict(\n",
    "            {\n",
    "                'linear 1': nn.Linear(2, 25),\n",
    "                'relu 1': nn.ReLU(),\n",
    "                'linear 2': nn.Linear(25, 25),\n",
    "                'relu 2': nn.ReLU(),\n",
    "                'linear 3': nn.Linear(25, 25),\n",
    "                'relu 3': nn.ReLU(),\n",
    "                'linear 4': nn.Linear(25, 1),\n",
    "                'last act': nn.Tanh(),\n",
    "            }\n",
    "        )\n",
    "        )\n",
    "\n",
    "    def backward(self, d_loss):\n",
    "        return self.f.backward(d_loss)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Train##########\n",
      "0\n",
      "Epoch 1, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 2, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 3, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 4, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 5, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 6, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 7, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 8, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 9, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 10, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 11, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 12, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 13, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 14, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 15, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 16, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 17, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 18, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 19, Loss=2.5630, Training_Acc=1.0000\n",
      "0\n",
      "Epoch 20, Loss=2.5630, Training_Acc=1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0731990965b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/deep-learning-project/mini_project_2/fwk/neural_nets/mse.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grads'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-727a81950cef>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, d_loss)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/deep-learning-project/mini_project_2/fwk/neural_nets/sequential.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, d_loss)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# Add grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mderivative\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Data\n",
    "X, Y, y_hot = data.generate_data()\n",
    "\n",
    "# Use case\n",
    "model = CustomNet()\n",
    "criterion = nn.MSE()\n",
    "\n",
    "eta = 0.1 / len(X)  # learning rate\n",
    "optimizer = optim.SGD(model.param(), eta=eta)\n",
    "\n",
    "losses = []\n",
    "step = len(X)\n",
    "print(\"#\" * 10 + 'Train' + \"#\" * 10)\n",
    "for i in range(N_EPOCHS):\n",
    "    \n",
    "    preds = []\n",
    "    avg_loss = 0\n",
    "    error = 0\n",
    "    \n",
    "    for n in range(step):\n",
    "        # Forward\n",
    "        output = model(X[n])\n",
    "        loss = criterion(output, Y[n])\n",
    "        avg_loss += loss.item() / step\n",
    "        \n",
    "    \n",
    "        # Compute error\n",
    "        if output.max(0)[1].item() != Y[n].max(0)[1].item():\n",
    "            error += 1\n",
    "            \n",
    "\n",
    "        preds.append(output.max(0)[1].item())\n",
    "        # Backward\n",
    "        model.zero_grad()\n",
    "        loss.backward(model)\n",
    "\n",
    "    print(error)\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "    # Decrease step size\n",
    "    optimizer.set_eta(eta / (1 + (2 / (i + 1))))\n",
    "    \n",
    "    #plt.scatter([x[0].item() for x in X], [x[1].item() for x in X], c=preds)\n",
    "    #plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # Print loss\n",
    "    print(\"Epoch %d, Loss=%.4f, Training_Acc=%.4f\" % (i + 1, avg_loss, (step - error) / step))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[0].item() for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test\n",
    "print(\"#\" * 10 + 'Test' + \"#\" * 10)\n",
    "# Data\n",
    "X_test, Y_test = data.generate_data()\n",
    "test_error = 0\n",
    "avg_test_loss = 0\n",
    "for i in range(len(X_test)):\n",
    "    # Forward\n",
    "    output = model(X_test[i])\n",
    "    loss = criterion(output, Y_test[i])\n",
    "    avg_test_loss += loss.item() / len(X_test)\n",
    "\n",
    "    # Compute error\n",
    "    if output.max(0)[1].item() != Y[i].max(0)[1].item():\n",
    "        test_error += 1\n",
    "\n",
    "print(\"Loss=%.4f, Test_Acc=%.4f\" % (avg_test_loss, (step - test_error) / step))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
